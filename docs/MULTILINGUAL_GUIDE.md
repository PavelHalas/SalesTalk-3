# Multilingual Support Guide

**Status**: Phase 5.1 Complete - Detection & Normalization  
**Languages Supported**: Czech (cs), English (en)  
**Last Updated**: 2025-11-21

---

## Overview

The SalesTalk classification system supports **Czech language queries** with automatic detection and normalization to canonical English tokens. This enables Czech users to ask business questions in their native language while maintaining a single, consistent classification schema.

### Key Features

‚úÖ **Diacritic-free support** - Works with or without h√°ƒçky and ƒç√°rky  
‚úÖ **Automatic detection** - No language parameter required  
‚úÖ **Transparent normalization** - Czech ‚Üí English tokens pre-classification  
‚úÖ **Single schema** - All outputs use canonical English tokens  
‚úÖ **Performance** - <100ms overhead for detection + normalization  
‚úÖ **Observable** - Full telemetry tracking per language  

---

## Architecture

```
User Question (Czech or English)
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Language Detection             ‚îÇ
‚îÇ  - Stopword matching (primary)  ‚îÇ
‚îÇ  - Diacritic hints (secondary)  ‚îÇ
‚îÇ  - Embedding (fallback)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Normalization (Czech only)     ‚îÇ
‚îÇ  - Strip diacritics             ‚îÇ
‚îÇ  - Longest-match-first lookup   ‚îÇ
‚îÇ  - Czech ‚Üí English tokens       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Classification (language-agnostic) ‚îÇ
‚îÇ  - AI adapter receives English  ‚îÇ
‚îÇ  - Existing pipeline unchanged  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
Canonical JSON (English tokens)
```

---

## Usage

### Environment Variables

Enable Czech language support by setting:

```bash
export ENABLE_LANG_DETECT=true
```

Optional configuration:

```bash
# Custom normalization map path
export CZ_NORMALIZATION_MAP_PATH=/path/to/cz_mapping.json

# Detection confidence threshold (default: 0.8)
export LANG_DETECT_CONFIDENCE_THRESHOLD=0.9

# Enable translation fallback for low-confidence cases
export ENABLE_TRANSLATION_FALLBACK=false

# Enable language-aware caching
export ENABLE_LANG_CACHE=true
```

### API Request (No Change)

Users simply submit questions in their preferred language:

```json
POST /classify
{
  "question": "Jak√© jsou na≈°e tr≈æby v Q3?"
}
```

### API Response

The response includes language metadata when multilingual is enabled:

```json
{
  "classification": {
    "intent": "what",
    "subject": "revenue",
    "measure": "revenue",
    "time": {
      "period": "Q3",
      "granularity": "quarter"
    },
    "confidence": {
      "overall": 0.92
    }
  },
  "metadata": {
    "latencyMs": 450,
    "normalizationOverheadMs": 35,
    "provider": "ollama",
    "language": {
      "detected_language": "cs",
      "language_confidence": 1.0,
      "detection_method": "stopword+diacritic",
      "has_diacritics": true,
      "normalization_coverage": 0.83,
      "replacements_count": 5,
      "categories_used": ["intents", "subjects", "metrics", "time_periods"]
    },
    "originalQuestion": "Jak√© jsou na≈°e tr≈æby v Q3?",
    "normalizedQuestion": "what jsou nase revenue v Q3?"
  }
}
```

---

## Examples

### Czech with Diacritics

**Input:**
```
"Jak√© jsou na≈°e tr≈æby v Q3?"
```

**Detection:**
- Language: `cs`
- Confidence: `1.0` (stopword + diacritic boost)
- Method: `stopword+diacritic`

**Normalization:**
- `Jak√©` ‚Üí `what`
- `tr≈æby` ‚Üí `revenue`
- `Q3` ‚Üí `Q3`

**Classification Output:**
```json
{
  "intent": "what",
  "subject": "revenue",
  "measure": "revenue",
  "time": {"period": "Q3", "granularity": "quarter"}
}
```

---

### Czech WITHOUT Diacritics (Mandatory Support)

**Input:**
```
"Jake jsou nase trzby v Q3?"
```

**Detection:**
- Language: `cs`
- Confidence: `1.0` (stopword matching without diacritics)
- Method: `stopword`

**Normalization:**
- `Jake` ‚Üí `what`
- `trzby` ‚Üí `revenue`
- `Q3` ‚Üí `Q3`

**Classification Output:** *(identical to above)*
```json
{
  "intent": "what",
  "subject": "revenue",
  "measure": "revenue",
  "time": {"period": "Q3", "granularity": "quarter"}
}
```

---

### English (Unchanged)

**Input:**
```
"What is our revenue in Q3?"
```

**Detection:**
- Language: `en`
- Confidence: `0.7`
- Method: `stopword`

**Normalization:** *(skipped for English)*

**Classification Output:**
```json
{
  "intent": "what",
  "subject": "revenue",
  "measure": "revenue",
  "time": {"period": "Q3", "granularity": "quarter"}
}
```

---

## Czech Language Coverage

### Supported Phrases (320+ mappings)

#### Subjects
- trzby/tr≈æby ‚Üí revenue
- zakaznici/z√°kazn√≠ci ‚Üí customers
- objednavky/objedn√°vky ‚Üí orders
- prodeje ‚Üí sales
- marze/mar≈æe ‚Üí margin
- zisk ‚Üí profit

#### Metrics
- mira odlivu/m√≠ra odlivu ‚Üí churn_rate
- prumerna hodnota objednavky/pr≈Ømƒõrn√° hodnota objedn√°vky ‚Üí aov
- MRR, ARR, LTV, NPS, CAC ‚Üí (unchanged)

#### Intents
- co, jaky/jak√Ω ‚Üí what
- proc/proƒç ‚Üí why
- porovnat ‚Üí compare
- trend ‚Üí trend
- predpoved/p≈ôedpovƒõƒè ‚Üí forecast
- zebricek/≈æeb≈ô√≠ƒçek ‚Üí rank

#### Time Periods
- dnes ‚Üí today
- vcera/vƒçera ‚Üí yesterday
- tento tyden/t√Ωden ‚Üí this_week
- minuly mesic/minul√Ω mƒõs√≠c ‚Üí last_month
- letosni rok/leto≈°n√≠ rok ‚Üí this_year
- Q1, Q2, Q3, Q4 ‚Üí (unchanged)

#### Dimensions
- aktivni/aktivn√≠ ‚Üí active
- neaktivni/neaktivn√≠ ‚Üí inactive
- SMB, Enterprise, EMEA ‚Üí (unchanged)

---

## Performance

### Latency Breakdown

| Component | Target | Typical |
|-----------|--------|---------|
| Language Detection | <10ms p95 | ~5ms |
| Normalization | <50ms p95 | ~15-30ms |
| **Total Overhead** | **<100ms p95** | **~35-50ms** |

### Coverage Metrics

- **Detection Accuracy**: ‚â•98% (with/without diacritics)
- **Normalization Coverage**: ‚â•90% common phrases
- **Czech Stopwords**: 40+ diacritic-free variants
- **Mapping Entries**: 320+ Czech‚ÜíEnglish phrases

---

## Testing

### Unit Tests

Run diacritic utilities tests:
```bash
cd backend
pytest tests/lambda/test_diacritic_utils.py -v
```

Expected: **22/22 passing**

### Integration Tests

Test full detection + normalization:
```bash
cd backend
python tests/lambda/test_czech_integration.py
```

Expected: **7/7 passing** (with/without diacritics)

### Classify Handler Tests

Test classify handler integration:
```bash
cd backend
python tests/lambda/test_classify_czech_integration.py
```

Expected: **4/4 passing**

---

## Implementation Details

### Language Detection Strategy

**Primary: Stopword Matching (Diacritic-Free)**
- Czech stopwords: `je`, `jsou`, `byl`, `v`, `na`, `proc`, `jaky`, `minuly`, etc.
- Match threshold: ‚â•2 Czech stopwords OR ‚â•30% stopword density
- Confidence: 0.65‚Äì0.85 base

**Secondary: Diacritic Pattern Boost**
- If diacritics present (ƒç, ≈°, ≈æ, ≈ô, √°, √©, √≠, etc.), boost confidence by +0.15
- Overrides English detection if diacritics found

**Fallback: Embedding Similarity** *(future)*
- For ambiguous short queries (<5 words, no stopwords)
- Currently returns stopword result

### Normalization Algorithm

1. **Preprocess**: `strip_diacritics(input)` ‚Üí diacritic-free text
2. **Normalize**: `lowercase` + `whitespace collapse`
3. **Match**: Longest-match-first lookup in `cz_mapping.json`
4. **Replace**: Czech phrase ‚Üí English canonical token
5. **Track**: Coverage, replacements, categories used

**Example Flow:**
```
Input:     "Jak√© jsou na≈°e tr≈æby v Q3?"
Strip:     "Jake jsou nase trzby v Q3?"
Normalize: "jake jsou nase trzby v q3?"
Match:     jake‚Üíwhat, trzby‚Üírevenue, q3‚ÜíQ3
Output:    "what jsou nase revenue v Q3?"
```

---

## Module Reference

### `backend/lambda/normalization/diacritic_utils.py`

Core diacritic handling utilities.

**Functions:**
- `strip_diacritics(text: str) -> str` - Remove h√°ƒçky and ƒç√°rky
- `contains_czech_diacritics(text: str) -> bool` - Check for diacritics
- `normalize_czech_text(text: str) -> str` - Full normalization pipeline

**Character Mappings:**
- H√°ƒçky: ƒç‚Üíc, ƒè‚Üíd, ƒõ‚Üíe, ≈à‚Üín, ≈ô‚Üír, ≈°‚Üís, ≈•‚Üít, ≈æ‚Üíz
- ƒå√°rky: √°‚Üía, √©‚Üíe, √≠‚Üíi, √≥‚Üío, √∫‚Üíu, √Ω‚Üíy
- Special: ≈Ø‚Üíu

### `backend/lambda/detection/language_detector.py`

Language detection engine.

**Functions:**
- `detect_language(text: str) -> LanguageDetectionResult`
- `is_czech(text: str) -> bool`
- `get_language_code(text: str) -> str`

**LanguageDetectionResult:**
```python
@dataclass
class LanguageDetectionResult:
    language: str          # 'cs' or 'en'
    confidence: float      # 0.0 to 1.0
    method: str           # 'stopword', 'diacritic', 'embedding'
    details: Dict         # Debug info
```

### `backend/lambda/normalization/cz_normalizer.py`

Czech-to-English normalization.

**Functions:**
- `normalize_czech_query(text: str) -> NormalizationResult`
- `quick_normalize(text: str) -> str`
- `get_coverage(text: str) -> float`

**NormalizationResult:**
```python
@dataclass
class NormalizationResult:
    original_text: str
    normalized_text: str
    coverage: float                    # 0.0 to 1.0
    replacements: Dict[str, str]       # Czech ‚Üí English
    categories_used: List[str]         # Mapping categories
```

### `backend/lambda/normalization/cz_mapping.json`

Czech‚ÜíEnglish phrase dictionary (320+ entries).

**Categories:**
- `subjects`: Business domain entities
- `metrics`: KPIs and measurements
- `intents`: Query types
- `time_periods`: Temporal references
- `time_windows`: Rolling windows (ytd, l3m, etc.)
- `dimensions`: Filters and groupings
- `granularity`: Time units

---

## Observability

### Logging

All Czech classifications emit structured logs:

```python
logger.info(
    "Czech question normalized",
    extra={
        "tenant_id": "acme-001",
        "request_id": "uuid",
        "original": "Jak√© jsou...",
        "normalized": "what jsou...",
        "coverage": 0.83,
        "language_confidence": 1.0
    }
)
```

### Metadata Tracking

Every Czech classification includes:

```json
{
  "language": {
    "detected_language": "cs",
    "language_confidence": 1.0,
    "detection_method": "stopword+diacritic",
    "has_diacritics": true,
    "normalization_coverage": 0.83,
    "replacements_count": 5,
    "categories_used": ["intents", "subjects", "metrics"]
  },
  "originalQuestion": "...",
  "normalizedQuestion": "...",
  "normalizationOverheadMs": 35
}
```

---

## Roadmap

### ‚úÖ Phase 5.1: Detection & Normalization (COMPLETE)
- Diacritic utilities
- Language detector
- Czech normalizer
- Classify handler integration
- Unit & integration tests

### üîÑ Phase 5.2: Taxonomy Localization (Next)
- Extend taxonomy with Czech translations
- Both diacritic and diacritic-free variants
- All 12 subjects + shared dimensions

### üìã Phase 5.4: Testing & Validation
- Czech test suite (80-100 questions)
- 50/50 split: diacritic vs diacritic-free
- Evaluation harness with accuracy metrics

### üîÆ Future Phases
- Prompt adaptation (Czech examples)
- Confidence calibration
- Translation fallback
- Language-aware caching
- Multilingual telemetry dashboard

---

## Troubleshooting

### Czech not detected

**Problem**: Czech question classified as English

**Solutions:**
1. Check `ENABLE_LANG_DETECT=true` is set
2. Verify Czech stopwords present (je, jsou, proc, jaky, etc.)
3. Review detection logs for confidence scores
4. Try adding more Czech-specific words

### Low normalization coverage

**Problem**: `normalization_coverage < 0.5`

**Solutions:**
1. Check `cz_mapping.json` for missing phrases
2. Add new mappings to appropriate categories
3. Use diacritic-free keys in mapping file
4. Review `replacements` field to see what matched

### Performance degradation

**Problem**: Latency >100ms overhead

**Solutions:**
1. Enable `ENABLE_LANG_CACHE=true`
2. Pre-compile normalization patterns (done at Lambda startup)
3. Review CloudWatch metrics for p95 latencies
4. Consider async detection for high-volume scenarios

---

## Contributing

### Adding Czech Synonyms

1. Identify unmapped Czech phrase in logs
2. Strip diacritics: `"m√≠ra odlivu"` ‚Üí `"mira odlivu"`
3. Add to `cz_mapping.json` with English token
4. Add test case to `test_cz_normalizer.py`
5. Verify coverage increases

### Testing New Phrases

```python
from normalization.cz_normalizer import normalize_czech_query

result = normalize_czech_query("Proc klesla mira odlivu?")
print(f"Coverage: {result.coverage}")
print(f"Replacements: {result.replacements}")
```

---

## References

- [DEVELOPMENT_PLAN_CZ.md](../docs/DEVELOPMENT_PLAN_CZ.md) - Full implementation plan
- [backend/lambda/README.md](../backend/lambda/README.md) - Lambda handler docs
- [E2E_TESTING.md](../E2E_TESTING.md) - Testing guide

---

**Questions?** See `.github/agents/Architect.md` for architecture details.
